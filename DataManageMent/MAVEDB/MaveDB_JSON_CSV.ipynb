{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernel_info": {
      "name": "python3.9-noteable"
    },
    "kernelspec": {
      "display_name": "Python 3.9 (Noteable)",
      "identifier": "noteable",
      "language": "python",
      "language_version": "3.9",
      "name": "python3.9-noteable"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "705afaf0",
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "source": "import pandas as pd\nimport json\nimport glob\nimport os\n\n# Corrected the directory path to include a slash at the end\n# directory_path = '<PATH>'\n\n# Use os.path.dirname(os.path.abspath(__file__)) to get the current directory of the script\ndirectory_path = os.path.dirname(os.path.abspath(__file__)) + '/'\n\n\n\n# Using glob.glob to match the JSON file extension\njson_files = glob.glob(directory_path + '*.json')\n\ndataframes = []\n\nfor file_path in json_files:\n    with open(file_path, 'r') as file:\n        data = json.load(file)\n        data = [data] if isinstance(data, dict) else data\n        df = pd.json_normalize(data)\n\n        gene_name = df['targetGene.name'].iloc[0] if 'targetGene.name' in df.columns else None\n\n        # Check if 'mapped_scores' is in the DataFrame and it's not empty\n        if 'mapped_scores' in df.columns and not df['mapped_scores'].isnull().all():\n            # Extracting data from 'mapped_scores'\n            for scores in df['mapped_scores'].dropna():\n                extracted_data = [{\n                    # 'gene_name': gene_name,\n                    # 'start_value': item.get('post_mapped', {}).get('variation', {}).get('location', {}).get('interval', {}).get('start', {}).get('value'),\n                    'end_value': item.get('post_mapped', {}).get('variation', {}).get('location', {}).get('interval', {}).get('end', {}).get('value'),\n                    'Ref': item.get('post_mapped', {}).get('vrs_ref_allele_seq'),\n                    'Alt': item.get('post_mapped', {}).get('variation', {}).get('state', {}).get('sequence'),\n                    'Functional score': item.get('score')\n                } for item in scores if item.get('post_mapped')]\n\n                # Only append if extracted_data is not empty\n                if extracted_data:\n                    df_extracted = pd.DataFrame(extracted_data)\n                    dataframes.append(df_extracted)\n\n# Concatenate all the DataFrames into one if dataframes is not empty\nif dataframes:\n    final_df = pd.concat(dataframes, ignore_index=True)\n    # Export the final DataFrame to a CSV file\n    final_csv_path = directory_path + 'MaveDV_data.csv'\n    final_df.to_csv(final_csv_path, index=False)\nelse:\n    print(\"No dataframes were created, please check your JSON structure or 'mapped_scores' content.\")",
      "outputs": []
    },
    {
      "id": "4aab1864-62bb-48a1-8465-627f68196333",
      "cell_type": "markdown",
      "source": "## Analysis of 'MaveDB_JSON_CSV.ipynb' Notebook\n\nThe notebook 'MaveDB_JSON_CSV.ipynb' contains a Python script designed to process JSON files and convert them into a structured CSV format. Here's a breakdown of the key steps and components of the script:\n\n1. **Importing Libraries:** The script begins by importing necessary libraries - pandas for data manipulation, json for parsing JSON files, glob for file path matching, and os for operating system interactions.\n\n2. **Setting Directory Path:** The directory path for the JSON files is set using `os.path.dirname(os.path.abspath(__file__))`, ensuring the script works with the current directory of the script.\n\n3. **Reading JSON Files:** The script uses `glob.glob` to find all JSON files in the specified directory. It then iterates through these files, loading and normalizing the JSON data into pandas DataFrames.\n\n4. **Data Extraction and Transformation:** The script extracts specific fields from the JSON data, focusing on 'end_value', 'Ref', 'Alt', and 'Functional score'. It handles nested JSON structures and conditional data extraction.\n\n5. **Concatenating DataFrames:** If any data is extracted, the script concatenates these into a single DataFrame.\n\n6. **Exporting to CSV:** Finally, the script exports the consolidated DataFrame to a CSV file named 'MaveDV_data.csv'.\n\nThis script is a comprehensive solution for converting JSON data into a structured CSV format, suitable for further data analysis or integration into data pipelines.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    },
    {
      "id": "9b47d6a6-9bbe-4517-bfd6-a545cd86f8f9",
      "cell_type": "markdown",
      "source": "## Analysis of 'MaveDB_JSON_CSV.ipynb' Notebook\n\nThe notebook 'MaveDB_JSON_CSV.ipynb' contains a Python script designed to process JSON files and convert them into a structured CSV format. Here's a breakdown of the key steps and components of the script:\n\n1. **Importing Libraries:** The script begins by importing necessary libraries - pandas for data manipulation, json for parsing JSON files, glob for file path matching, and os for operating system interactions.\n\n2. **Setting Directory Path:** The directory path for the JSON files is set using `os.path.dirname(os.path.abspath(__file__))`, ensuring the script works with the current directory of the script.\n\n3. **Reading JSON Files:** The script uses `glob.glob` to find all JSON files in the specified directory. It then iterates through these files, loading and normalizing the JSON data into pandas DataFrames.\n\n4. **Data Extraction and Transformation:** The script extracts specific fields from the JSON data, focusing on 'end_value', 'Ref', 'Alt', and 'Functional score'. It handles nested JSON structures and conditional data extraction.\n\n5. **Concatenating DataFrames:** If any data is extracted, the script concatenates these into a single DataFrame.\n\n6. **Exporting to CSV:** Finally, the script exports the consolidated DataFrame to a CSV file named 'MaveDV_data.csv'.\n\nThis script is a comprehensive solution for converting JSON data into a structured CSV format, suitable for further data analysis or integration into data pipelines.",
      "metadata": {
        "noteable": {
          "cell_type": "markdown"
        }
      }
    }
  ]
}